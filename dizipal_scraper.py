# -*- coding: utf-8 -*-
import re
from bs4 import BeautifulSoup
import json
from requests_handler import request_handler # Ã–zel istek yÃ¶neticimizi iÃ§eri aktar

class DizipalScraper:
    def __init__(self):
        # DiziPalOrijinal.kt'den ana URL'i alÄ±yoruz
        self.main_url = "https://dizipal936.com" # GÃ¼ncel Dizipal adresini buraya girin!
        self.cKey = None
        self.cValue = None

    async def init_session(self): # Kotlin'deki suspend fun benzeri asenkron
        if self.cKey and self.cValue:
            print("Oturum zaten baÅŸlatÄ±ldÄ±.")
            return True

        print("ğŸ”„ Oturum baÅŸlatÄ±lÄ±yor: Ã§erezler, cKey ve cValue alÄ±nÄ±yor...")

        headers = {
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
            "User-Agent": request_handler.user_agent, # Bypass sonrasÄ± User-Agent'i kullan
            "Referer": f"{self.main_url}/",
        }

        # Cloudflare ve diÄŸer korumalarÄ± otomatik olarak handle etmesi iÃ§in
        resp = request_handler.get(self.main_url, headers=headers, timeout=120, handle_protection=True)
        if not resp:
            print("Dizipal ana sayfasÄ± alÄ±namadÄ±.")
            return False

        soup = BeautifulSoup(resp.text, 'html.parser')
        c_key_input = soup.select_one("input[name=cKey]")
        c_value_input = soup.select_one("input[name=cValue]")

        if c_key_input and c_value_input:
            self.cKey = c_key_input.get('value')
            self.cValue = c_value_input.get('value')
            print(f"cKey: {self.cKey}, cValue: {self.cValue}")
        else:
            print("cKey veya cValue sayfada bulunamadÄ±.")
            return False
        return True

    async def get_main_page_content(self, page=1, request_name="Yeni Eklenen BÃ¶lÃ¼mler", request_data=""):
        await self.init_session() # Oturumu baÅŸlattÄ±ÄŸÄ±mÄ±zdan emin ol

        kanallar_list = [
            "Exxen Diziler", "Disney+ Dizileri", "Netflix Dizileri",
            "Amazon Dizileri", "Apple TV+ Dizileri", "Max Dizileri",
            "Hulu Dizileri", "TOD Dizileri", "Tabii Dizileri"
        ]

        post_data = {
            "cKey": self.cKey,
            "cValue": self.cValue,
            "currentPage": str(page),
            "releaseYearStart": "1923",
            "releaseYearEnd": "2025"
        }
        headers = {
            "User-Agent": request_handler.user_agent, # Bypass sonrasÄ± User-Agent'i kullan
            "Referer": f"{self.main_url}/",
            "X-Requested-With": "XMLHttpRequest", # Genellikle AJAX POST istekleri iÃ§in gereklidir
            "Accept": "application/json, text/javascript, */*; q=0.01",
            "Content-Type": "application/x-www-form-urlencoded; charset=UTF-8"
        }

        response = None
        if any(k in request_name for k in kanallar_list): # Kanal bazlÄ± listeleme
            post_data.update({"channelId": request_data, "languageId": "2,3,4"})
            response = request_handler.post(f"{self.main_url}/bg/getserielistbychannel", data=post_data, headers=headers)
        elif "Yeni Eklenenler" in request_name: # Yeni eklenen diziler
            post_data.update({"categoryIdsComma[]": request_data, "orderType": "date_asc"})
            response = request_handler.post(f"{self.main_url}/bg/findseries", data=post_data, headers=headers)
        elif "Yeni Eklenen BÃ¶lÃ¼mler" in request_name: # Ana sayfadaki bÃ¶lÃ¼mler (GET isteÄŸi)
            response = request_handler.get(self.main_url, headers=headers) # Ana sayfa HTML'ini Ã§ek
        elif "Yeni Filmler" in request_name: # Yeni eklenen filmler
            post_data.update({"categoryIdsComma[]": request_data, "orderType": "date_desc"})
            response = request_handler.post(f"{self.main_url}/bg/findmovies", data=post_data, headers=headers)
        else: # VarsayÄ±lan (IMDb puanÄ±na gÃ¶re diziler vb.)
            post_data.update({"categoryIdsComma[]": request_data, "orderType": "imdb_desc"})
            response = request_handler.post(f"{self.main_url}/bg/findseries", data=post_data, headers=headers)

        if not response:
            print(f"Ä°Ã§erik alÄ±namadÄ±: {request_name}")
            return []

        body_text = response.text
        html_fragment = ""
        try:
            # YanÄ±t JSON ise 'data.html' alanÄ±nÄ± Ã§ek
            json_data = json.loads(body_text)
            if 'data' in json_data and 'html' in json_data['data']:
                html_fragment = json_data['data']['html']
            else:
                html_fragment = body_text # JSON ama 'data.html' yoksa tÃ¼m body'yi kullan
        except json.JSONDecodeError:
            html_fragment = body_text # JSON deÄŸilse doÄŸrudan HTML olarak iÅŸleme al

        soup = BeautifulSoup(html_fragment, 'html.parser')

        home_results = []
        if "Yeni Eklenen BÃ¶lÃ¼mler" in request_name:
            # Kotlin kodundaki seÃ§ici
            links = soup.select("div.overflow-auto a")
        else:
            # Genel film/dizi listeleri iÃ§in seÃ§ici
            links = soup.select("div.prm-borderb a") # Dizipal HTML yapÄ±sÄ±na gÃ¶re ayarlanmalÄ±

        for link_tag in links:
            href = link_tag.get('href')
            title = link_tag.get_text(strip=True)
            if href:
                # BaÄŸlantÄ± tam URL deÄŸilse ana URL ile birleÅŸtir
                full_url = href if href.startswith('http') else self.main_url + href
                home_results.append({"title": title, "url": full_url})

        return home_results
