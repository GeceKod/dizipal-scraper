# -*- coding: utf-8 -*-
import re
from bs4 import BeautifulSoup
import json
from requests_handler import request_handler # Ã–zel istek yÃ¶neticimizi iÃ§eri aktar
from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes
from cryptography.hazmat.backends import default_backend
import base64

class DizipalScraper:
    def __init__(self):
        self.main_url = "https://dizipal936.com"
        self.cKey = None
        self.cValue = None
        # Orijinal Kotlin kodundan alÄ±nan sabit ÅŸifre Ã§Ã¶zme anahtarÄ±
        self.decryption_key = "3hPn4uCjTVtfYWcjIcoJQ4cL1WWk1qxXI39egLYOmNv6IblA7eKJz68uU3eLzux1biZLCms0quEjTYniGv5z1JcKbNIsDQFSeIZOBZJz4is6pD7UyWDggWWzTLBQbHcQFpBQdClnuQaMNUHtLHTpzCvZy33p6I7wFBvL4fnXBYH84aUIyWGTRvM2G5cfoNf4705tO2kv"

    def _decrypt_aes(self, salt_hex, iv_hex, ciphertext_base64):
        """DiziPalOrijinal.kt'deki decrypt fonksiyonunun Python'a uyarlanmasÄ±."""
        try:
            salt = bytes.fromhex(salt_hex)
            iv = bytes.fromhex(iv_hex)
            ciphertext = base64.b64decode(ciphertext_base64)
            passphrase = self.decryption_key

            # PBKDF2 anahtar tÃ¼retme (999 iterasyon, SHA512, 256 bit = 32 byte anahtar)
            kdf = PBKDF2HMAC(
                algorithm=hashes.SHA512(),
                length=32,
                salt=salt,
                iterations=999,
                backend=default_backend()
            )
            key = kdf.derive(passphrase.encode('utf-8'))

            # AES/CBC/PKCS5Padding ÅŸifre Ã§Ã¶zme
            cipher = Cipher(algorithms.AES(key), modes.CBC(iv), backend=default_backend())
            decryptor = cipher.decryptor()
            padded_data = decryptor.update(ciphertext) + decryptor.finalize()

            # PKCS#7 (veya PKCS#5) padding'i kaldÄ±r
            pad_len = padded_data[-1]
            if not 1 <= pad_len <= 16:
                raise ValueError("GeÃ§ersiz padding uzunluÄŸu.")
            if not all(p == pad_len for p in padded_data[-pad_len:]):
                raise ValueError("GeÃ§ersiz padding.")
            
            decrypted_content = padded_data[:-pad_len]
            return decrypted_content.decode('utf-8')
        except Exception as e:
            print(f"Åžifre Ã§Ã¶zme baÅŸarÄ±sÄ±z oldu: {e}")
            return None

    async def init_session(self):
        if self.cKey and self.cValue:
            print("Oturum zaten baÅŸlatÄ±ldÄ±.")
            return True
        print("ðŸ”„ Oturum baÅŸlatÄ±lÄ±yor: Ã§erezler, cKey ve cValue alÄ±nÄ±yor...")
        headers = {
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
            "User-Agent": request_handler.user_agent,
            "Referer": f"{self.main_url}/",
        }
        resp = request_handler.get(self.main_url, headers=headers, timeout=120, handle_protection=True)
        if not resp:
            print("Dizipal ana sayfasÄ± alÄ±namadÄ±.")
            return False
        soup = BeautifulSoup(resp.text, 'html.parser')
        c_key_input = soup.select_one("input[name=cKey]")
        c_value_input = soup.select_one("input[name=cValue]")
        if c_key_input and c_value_input:
            self.cKey = c_key_input.get('value')
            self.cValue = c_value_input.get('value')
            print(f"cKey: {self.cKey}, cValue: {self.cValue}")
            return True
        else:
            print("cKey veya cValue sayfada bulunamadÄ±.")
            return False

    async def get_main_page_content(self, page=1, request_name="Yeni Eklenen BÃ¶lÃ¼mler"):
        """Ana sayfadaki ve kategorilerdeki iÃ§erik listelerini Ã§eker."""
        await self.init_session()
        
        headers = {"User-Agent": request_handler.user_agent, "Referer": f"{self.main_url}/"}
        
        if "Yeni Eklenen BÃ¶lÃ¼mler" in request_name:
             response = request_handler.get(self.main_url, headers=headers)
        else:
            print(f"'{request_name}' iÃ§in listeleme mantÄ±ÄŸÄ± henÃ¼z eklenmedi.")
            return []

        if not response:
            print(f"Ä°Ã§erik alÄ±namadÄ±: {request_name}")
            return []

        soup = BeautifulSoup(response.text, 'html.parser')
        home_results = []
        
        links = soup.select("div.overflow-auto a")
        
        for link_tag in links:
            try:
                raw_href = link_tag.get('href')
                img_tag = link_tag.find("img")
                
                if not raw_href or not img_tag:
                    continue

                # --- GÃœNCELLENEN KISIM ---
                # HatalÄ± olan /bolum/ -> /series/ dÃ¶nÃ¼ÅŸtÃ¼rmesi kaldÄ±rÄ±ldÄ±.
                # ArtÄ±k ham bÃ¶lÃ¼m linkini doÄŸrudan kullanÄ±yoruz.
                href = raw_href
                # --- GÃœNCELLEME SONU ---
                
                full_url = href if href.startswith('http') else self.main_url + href
                
                # BaÅŸlÄ±k oluÅŸturma
                title_alt = img_tag.get('alt', '').strip()
                title_text_element = link_tag.find("div", class_="text-white")
                title_text = title_text_element.text.strip() if title_text_element else ""
                
                full_title = f"{title_alt} {title_text}".strip()
                
                home_results.append({"title": full_title, "url": full_url})
            except Exception as e:
                print(f"UyarÄ±: Bir bÃ¶lÃ¼m iÅŸlenirken hata oluÅŸtu, atlanÄ±yor. Hata: {e}")
                continue
            
        return home_results
    
    async def get_player_url(self, episode_url):
        """Verilen bÃ¶lÃ¼m URL'inden ÅŸifrelenmiÅŸ oynatÄ±cÄ± URL'ini Ã§Ã¶zer."""
        print(f"OynatÄ±cÄ± URL'i alÄ±nÄ±yor: {episode_url}")
        headers = {"Referer": self.main_url, "User-Agent": request_handler.user_agent}
        resp = request_handler.get(episode_url, headers=headers)
        
        if not resp:
            print(f"BÃ¶lÃ¼m sayfasÄ± alÄ±namadÄ±: {episode_url}")
            return None

        soup = BeautifulSoup(resp.text, 'html.parser')
        hidden_div = soup.select_one("div[data-rm-k]")
        
        if not (hidden_div and hidden_div.text):
            print("Sayfada ÅŸifreli veri (div[data-rm-k]) bulunamadÄ±.")
            return None
        
        try:
            json_data = json.loads(hidden_div.text)
            ciphertext = json_data.get("ciphertext")
            iv = json_data.get("iv")
            salt = json_data.get("salt")
            
            if not all([ciphertext, iv, salt]):
                print("JSON veri iÃ§inde gerekli anahtarlar (ciphertext, iv, salt) eksik.")
                return None

            decrypted_url = self._decrypt_aes(salt, iv, ciphertext)
            return decrypted_url
                except Exception as e:
            print(f"Åžifreli veri iÅŸlenirken hata oluÅŸtu: {e}")
            return None
